{"codeList":["# Simple configuration: only specifying the tokenizer name\nanalyzer_params = {\n    \"tokenizer\": \"jieba\",  # Use the default settings: dict=[\"_default_\"], mode=\"search\", hmm=true\n}\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"jieba\");\n","const analyzer_params = {\n    \"tokenizer\": \"jieba\",\n};\n","// go\n","# restful\nanalyzerParams='{\n  \"tokenizer\": \"jieba\"\n}'\n","# Custom configuration equivalent to the simple configuration above\nanalyzer_params = {\n    \"type\": \"jieba\",          # Tokenizer type, fixed as \"jieba\"\n    \"dict\": [\"_default_\"],     # Use the default dictionary\n    \"mode\": \"search\",          # Use search mode for improved recall (see mode details below)\n    \"hmm\": true                # Enable HMM for probabilistic segmentation\n}\n","// java\n","// javascript\n","// go\n","# restful\n","# Custom configuration with user-defined settings\nanalyzer_params = {\n    \"tokenizer\": {\n        \"type\": \"jieba\",           # Fixed tokenizer type\n        \"dict\": [\"customDictionary\"],  # Custom dictionary list; replace with your own terms\n        \"mode\": \"exact\",           # Use exact mode (non-overlapping tokens)\n        \"hmm\": false               # Disable HMM; unmatched text will be split into individual characters\n    }\n}\n","// java\n","// javascript\n","// go\n","# restful\n","analyzer_params = {\n    \"tokenizer\": {\n        \"type\": \"jieba\",\n        \"dict\": [\"结巴分词器\"],\n        \"mode\": \"exact\",\n        \"hmm\": False\n    }\n}\n","// java\n","// javascript\n","// go\n","# restful\n","['milvus', '结巴分词器', '中', '文', '测', '试']\n"],"headingContent":"Jieba","anchorList":[{"label":"Jieba","href":"Jieba","type":1,"isActive":false},{"label":"Configuración","href":"Configuration","type":2,"isActive":false},{"label":"Ejemplos","href":"Examples","type":2,"isActive":false}]}